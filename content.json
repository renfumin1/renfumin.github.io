[{"title":"04-MyISAM读写锁","date":"2017-05-10T10:34:16.000Z","path":"2017/05/10/2017-05-10-lock-04/","text":"1.MYISAM存储引擎下读锁和写锁是互斥的MYISAM存储引擎下读锁和写锁是互斥的，即当两个请求(一个申请写锁, 一个申请读锁)同时到达的情况下，MYISAM存储引擎只能设置写锁或者读锁，不能既设置写锁又设置读锁。 2.MYISAM存储引擎下写锁的优先级比较高缺省的情况下(默认情况下)，同一时间点上，同时到达两个进程，分别申请读锁和写锁的情况，MYSQL会优先给写锁。而且，如果读请求先到锁等待队列里面排队，写请求后到锁等待队列的话，也是优先给写锁，写锁处理完毕才给读锁。这是缺省情况下，mysql认为写比读更重要，所以做出的这种分配机制。 3.接下来我们尝试自己去观察下，事实是不是这样的吧？ A窗口先运行一个时间比较长的update操作，然后立即去执行B窗口的select操作，然后立即再去C窗口执行update操作。（A窗口运行的时候，B窗口的select先进入锁等待队列，C窗口的update后进入锁等待队列，观察在锁等待队列中B窗口的select 先到，C窗口的update后到的情况下，谁先执行？） 看实际操作图 : 由图中我们可以看到，在进入锁等待队列时，select先到队列等待的但却是最后执行的，update后到队列但却是先执行的，因此，可以说明，myisam 下默认对写的优先级比较高。 4.适用的场景Myisam引擎这种缺省情况下的机制，会有一个比较严重的问题，那就是对于大量的更新和查询操作的应用，因为写操作的优先级大于读操作，那就可能造成读锁很难获得读锁，一直阻塞在那边，直到写操作执行完毕，因此, myisam表比较适合读多写少的情况下。","tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://blog.renyimin.com/tags/MySQL/"}]},{"title":"03-MyISAM引擎下写锁的使用","date":"2017-05-09T13:20:19.000Z","path":"2017/05/09/2017-05-09-lock-03/","text":"1.MyISAM引擎下如何设置表锁: MyISAM在执行查询语句(SELECT)前，会自动给涉及的所有表加读锁，我们不需要手动去做任何的操作！ MyISAM在执行更新操作(UPDATE、DELETE、INSERT等)前，会自动给涉及的表加写锁，我们也不需要手动去做任何的操作，因此，只要给表设置myisam引擎，就可以了。 2.之前, 我们已经通过实际操做验证了MyISAM在执行查询语句（SELECT）前，会自动给涉及的所有表加读锁，并且不会阻塞其他进程对表的读操作,但是会堵塞其他进程对表的写操作； 接下来, 我们需要通过实际操作来验证：对 MyISAM表进行写操作时，会如之前说的那样阻塞其他用户对该表的读 写操作吗？ 3.开始前的小知识点 : 开始测试之前，我们需要知道一个小的知识点：因为接下来的测试的写操作执行速度太快，我们需要根据别的指标去判断当时是否发生了阻塞: 执行命令: show global status like ‘%locks%’ 是用来查看锁的争夺状况 上图中, 标注的地方 Table_locks_waited=0 ,它代表一共发生了0次不能立刻获得锁而需要等待的情况，接下来的测试，我们会通过判断测试前 Table_locks_waited 的值和测试后 Table_locks_waited 的值得对比来判断刚刚有没有发生阻塞情况。 4.准备工作: 先清空之前test表中的测试数据, 然后使用存储过程插入500W条数据:12345678910111213141516171819delimiter ;;create procedure myproc ()begindeclare num int ;set num = 0 ;while num &lt; 5000000 do insert into test (id, `name`)values ('', concat(\"name\", num)) ;set num = num + 1 ;endwhile ;end;;call myproc();drop procedure myproc; 注意, 此时由于在此过程中执行过查询总数的操作, 所以可能会出现锁等待, 因此需要重新查看Table_locks_waited的值 : 5.开始测试: A窗口在update时, 立即去B窗口执行select, 观察 : 初始值是8，测试完成后变成了9，说明发生了阻塞等待 A窗口在update时，立即去B窗口执行insert, 观察： 初始值是9，测试完成后变成了10，说明发生了阻塞等待 A窗口在update时，立即去B窗口执行delete, 观察： 初始值是10，测试完成后变成了11，说明发生了阻塞等待 A窗口在update时，立即去B窗口执行update, 观察： 初始值是11，测试完成后变成了12，说明发生了阻塞等待 6.综上，对 MyISAM表写操作，则会阻塞其他用户对该表的读写操作, 当一个线程获得对一个表的写锁后对表进行更新操作，其他线程的读、写操作（增删改查）都会等待，直到锁被释放为止。","tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://blog.renyimin.com/tags/MySQL/"}]},{"title":"01-MyISAM引擎下读锁的使用","date":"2017-05-09T11:21:11.000Z","path":"2017/05/09/2017-05-09-lock-02/","text":"1.MyISAM引擎下如何设置表锁: MyISAM在执行查询语句(SELECT)前，会自动给涉及的所有表加读锁，我们不需要手动去做任何的操作！ MyISAM在执行更新操作(UPDATE、DELETE、INSERT等)前，会自动给涉及的表加写锁，我们也不需要手动去做任何的操作，因此，只要给表设置myisam引擎，就可以了。 2.阻塞发生的场景 对MyISAM表读操作时候，不会阻塞其他用户对同一表的读请求，但会阻塞对同一表的写请求； 而对MyISAM表写操作，则会阻塞其他用户对该表的读写操作,也就是说, 当一个线程获得对一个表的写锁后可以对表进行更新操作; 但是其他线程的读、写操作都会等待，直到锁被释放为止; 3.接下来通过实践来观察下，对MyISAM表读操作时候，会如上面我们说的那样其他进程对该表的读请求不会阻塞, 而写请求会阻塞吗？ 先建立一张test表，存储引擎为myisam，字段为id, name，并插入几条数据 A窗口在select的时候特意暂停了12秒，然后立即去B窗口执行select, 观察： 在A窗口的查询操作没有结束之前，B窗口对该表进行查询，查询结果立刻出现，无需等待A窗口的查询结束注：sleep（4）是每条数据暂停4秒的意思，如果select的结果数据有1条就会暂停4秒，有3条就会暂停12秒 4.接下来通过实践来观察下，对MyISAM表读操作时候，会如上面我们说的那样其他进程对该表的读请求不会阻塞, 而写请求会阻塞吗？ A窗口在select的时候特意暂停12秒, 然后立即去B窗口执行update, 观察 : 在查询没有结束之前，update删除操作是处于一直等待状态，查询结束之后，update操作才开始执行 A窗口在select的时候特意暂停12秒, 然后立即去B窗口执行delete, 观察 : 在查询没有结束之前，delete删除操作是处于一直等待状态，查询结束之后，delete操作才开始执行 A窗口在select的时候特意暂停12秒, 然后立即去B窗口执行insert, 观察 : 在查询没有结束之前，insert操作是处于一直等待状态，查询结束之后，insert操作才开始执行 5.经过上面的4项测试，我们可以看到myisam表在执行查询操作的时候，其他进程对该表的读操作没有影响，但是写操作（增删改）会发生阻塞，直到第一个获得读锁的进程操作完成释放完读锁后，写操作才能进行。 mysql所用版本为5.5.53","tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://blog.renyimin.com/tags/MySQL/"}]},{"title":"01-锁的出现","date":"2017-05-09T04:10:01.000Z","path":"2017/05/09/2017-05-09-lock-01/","text":"1.Mysql中不同的存储引擎支持不同的锁机制 MyISAM和MEMORY存储引擎采用的表级锁 BDB采用的页面锁 InnoDB存储引擎采用的行级锁 2.从mysql-5.5.5开始,InnoDB作为默认存储引擎 3.Mysql锁出现的原因mysql中锁的出现，其实就是为了处理并发情况下出现的问题，所以，如果你的应用并发量比较小，可能很难看到一些锁等待，死锁的现象。 4.一些简单的常识 互斥：是说两件事不可能同时发生。 缺省：即默认。通常所说的缺省情况下，意思即默认情况下。","tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://blog.renyimin.com/tags/MySQL/"}]},{"title":"基于API的用户认证-03","date":"2017-04-14T05:31:16.000Z","path":"2017/04/14/2017-04-14-restful-03/","text":"JWT参考:http://blog.leapoahead.com/2015/09/06/understanding-jwt/其中的说法貌似就是, JWT不但可以解决客户端和服务端的验证问题, 也可以解决登录问题, token是有时效性的 http://www.tuicool.com/articles/R7Rj6r3 http://www.jianshu.com/p/576dbf44b2ae http://blog.rainy.im/2015/06/10/react-jwt-pretty-good-practice/ http://www.cnblogs.com/grissom007/p/6294746.html 单点登录（SSO）??? 别人给的连接,没事看看: https://mp.weixin.qq.com/s?__biz=MjM5OTA1MDUyMA==&amp;mid=2655437928&amp;idx=1&amp;sn=962865abc4721f66b7de0de6ea695d6b&amp;chksm=bd73081f8a048109f3c7e4dee2efc537044fa5d7a6fed916106bc939daf5d92ca1d2ca438dbf&amp;scene=0&amp;key=24ac2ab74d612457fd12342e95440ee60ec2a3862e2a28899d918f82a289a8887c111fe41775549c739295db4230daecbff3ae224c0da7c2edddaf3d0fa6eb3fad3adadb58bbc2a6169398af15c4ff03&amp;ascene=0&amp;uin=NzgyNzAwMTAx&amp;devicetype=iMac+MacBookPro12%2C1+OSX+OSX+10.12.4+build(16E195)&amp;version=12020610&amp;nettype=WIFI&amp;fontScale=100&amp;pass_ticket=uDBdbifrhzx7a4aYcr8c53dDjnBopizRj8t2uj9TiM2zo9lElcoqWoddfeX4acRM","tags":[{"name":"RESTful","slug":"RESTful","permalink":"http://blog.renyimin.com/tags/RESTful/"}]},{"title":"RESTful API安全设计 - 02","date":"2017-04-12T14:40:02.000Z","path":"2017/04/12/2017-04-12-restful-02/","text":"重放攻击1.重放攻击是计算机世界黑客常用的攻击方式之一，所谓重放攻击就是攻击者发送一个目的主机已接收过的包，来达到欺骗系统的目的，主要用于身份认证过程; 2.首先要明确一个事情，重放攻击是二次请求，黑客通过抓包获取到了请求的HTTP报文，然后黑客自己编写了一个类似的HTTP请求，发送给服务器。 也就是说服务器处理了两个请求，先处理了正常的HTTP请求，然后又处理了黑客发送的篡改过的HTTP请求。 基于timestamp的方案每次HTTP请求，都需要加上timestamp参数，然后把timestamp和其他参数一起进行数字签名。 因为一次正常的HTTP请求，从发出到达服务器一般都不会超过60s，所以服务器收到HTTP请求之后，首先判断时间戳参数与当前时间相比较，是否超过了60s，如果超过了则认为是非法的请求。 假如黑客通过抓包得到了我们的请求url： http://koastal.site/index/Info?uid=ZX07&amp;stime=1480862753&amp;sign=80b886d71449cb33355d017893720666 其中 $sign=md5($uid.$token.$stime); // 服务器通过uid从数据库中可读出token 一般情况下，黑客从抓包重放请求耗时远远超过了60s，所以此时请求中的stime参数已经失效了。 假设黑客修改$stime参数为当前的时间戳,虽然$stime可以满足了,但是sign参数对应的数字签名就会失效。 但这种方式的漏洞也是显而易见的，如果在60s之内进行重放攻击，那就没办法了，所以这种方式不能保证请求仅一次有效。基于nonce的方案(Number used once)nonce的意思是仅一次有效的随机字符串,要求每次请求时,该参数要保证不同,所以该参数一般与时间戳有关;我们这里为了方便起见,直接使用时间戳的16进制,实际使用时可以加上客户端的ip地址,mac地址等信息做个哈希之后,作为nonce参数。我们将每次请求的nonce参数存储到一个“集合”中，可以json格式存储到数据库或缓存中。每次处理HTTP请求时,首先判断该请求的nonce参数是否在该“集合”中,如果存在则认为是非法请求。 假如黑客通过抓包得到了我们的请求url: http://koastal.site/index/Info?uid=ZX07&amp;nonce=58442c21&amp;sign=80b886d71449cb33355d017893720666 其中 $sign=md5($uid.$token.$nonce); // 服务器通过uid从数据库中可读出token nonce参数在首次请求时,已经被存储到了服务器上的“集合”中,再次发送请求会被识别并拒绝。nonce参数作为数字签名的一部分,是无法篡改的,否则sign就会匹配失败。 这种方式也有很大的问题,那就是存储nonce参数的“集合”会越来越大,验证nonce是否存在“集合”中的耗时会越来越长。我们不能让nonce“集合”无限大,所以需要定期清理该“集合”,但是一旦该“集合”被清理,我们就无法验证被清理了的nonce参数了。也就是说,假设该“集合”平均1天清理一次的话,我们抓取到的该url,虽然当时无法进行重放攻击,但是我们还是可以每隔一天进行一次重放攻击的。而且存储24小时内所有请求的“nonce”参数,也是一笔不小的开销。 基于timestamp和nonce的方案nonce的一次性可以解决timestamp参数60s的问题,timestamp可以解决nonce参数“集合”越来越大的问题。 我们在timestamp方案的基础上,加上nonce参数,因为timstamp参数对于超过60s的请求都认为非法请求,所以我们只需要存储60s的nonce参数的“集合”即可。 假如黑客通过抓包得到了我们的请求url： http://koastal.site/index/Info?uid=ZX07&amp;stime=1480862753&amp;nonce=58442c21&amp;sign=80b886d71449cb33355d017893720666 其中 $sign=md5($uid.$token.$stime.$nonce); // 服务器通过uid从数据库中可读出token 如果在60s内,重放该HTTP请求,因为nonce参数已经在首次请求的时候被记录在服务器的nonce参数“集合”中,所以会被判断为非法请求。超过60s之后,stime参数就会失效。 综上,我们认为一次正常的HTTP请求发送不会超过60s,在60s之内的重放攻击可以由nonce参数保证;超过60s的重放攻击可以由stime参数保证;因为nonce参数只会在60s之内起作用,所以只需要保存60s之内的nonce参数即可。我们并不一定要每隔60s去清理该nonce参数的集合,只需要在新的nonce到来时,判断nonce集合最后一次修改时间,超过60s的话,就清空该集合,存放新的nonce参数集合。其实nonce参数集合可以存放的时间更久一些，但是最少是60s。 最后,自定义了一个验证流程(基于Laravel5.1):12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970&lt;?phpnamespace App\\Http\\Middleware;use Closure;use Illuminate\\Support\\Facades\\Config;use Illuminate\\Support\\Facades\\Input;use Illuminate\\Support\\Facades\\Redis;class CheckRequest&#123; const REPLAY_LIMIT_TIME = 60; /** * Handle an incoming request. * 客户端校验 * @param \\Illuminate\\Http\\Request $request * @param \\Closure $next * @return mixed */ public function handle($request, Closure $next) &#123; //必备参数 $needParams = [ 'restApi', 'timestrap', 'nonce', 'sign', 'data', ]; //获取参数 $params = Input::all(); //检查参数是否符合json规范 $params = json_decode($params['params'], true); if (json_last_error() != JSON_ERROR_NONE) &#123; return response()-&gt;json(res([], 102)); &#125; //丢失参数 $missParams = array_diff($needParams, array_keys($params)); if (!empty($missParams)) &#123; return response()-&gt;json(res([], 103, ['params'=&gt;implode(',', $missParams)])); &#125; extract($params); //开始非对称解码参数(如果参数进行了加密处理) //TODO //检测重放攻击 //请求时间和当前时间差距超过重放限制时间 if (($timestrap + self::REPLAY_LIMIT_TIME) &lt; time()) &#123; return response()-&gt;json(res([], 104)); &#125; //请求时间和当前时间差距未超过重放限制时间,则需要检查请求的唯一性 if (Redis::get('hh') == $nonce) &#123; return response()-&gt;json(res([], 105)); &#125; //API_KEY方式校验 $serverSign = md5($restApi . $timestrap . $nonce . Config::get('api.security_key')); if ($serverSign != $sign) &#123; return response()-&gt;json(res([], 106)); &#125; //后续操作 //$nonce数据缓存, 60秒失效 Redis::set('hh', $nonce); Redis::expire('hh', self::REPLAY_LIMIT_TIME); //TODO $params = json_decode($params['data'], true); $request-&gt;attributes-&gt;add(compact('params')); return $next($request); &#125;&#125; 参考:http://m.blog.csdn.net/article/details?id=53456696","tags":[{"name":"RESTful","slug":"RESTful","permalink":"http://blog.renyimin.com/tags/RESTful/"}]},{"title":"RESTful API安全设计 - 01","date":"2017-04-12T14:10:19.000Z","path":"2017/04/12/2017-04-12-restful-01/","text":"RESTful API简介 REST的全称是REpresentational State Transfer，表示 “表述性无状态传输”，无需session，所以每次请求都得带上身份认证信息。 rest是基于http协议的，也是无状态的。只是一种架构方式，所以它的安全特性都需我们自己实现，没有现成的。 建议所有的请求都通过https协议发送。 RESTful web services 概念的核心就是“资源”, 资源可以用 URI 来表示, 客户端使用 HTTP 协议定义的方法来发送请求到这些 URIs, 当然可能会导致这些被访问的 “资源” 状态的改变。 HTTP请求对应关系如下： 身份认证身份认证包含很多种，有HTTP Basic，HTTP Digest，API KEY，Oauth，JWK等方式，下面简单讲解下：1.HTTP Basic REST由于是无状态的传输，所以每一次请求都得带上身份认证信息; 身份认证的方式有很多种，第一种便是http basic，这种方式在客户端要求简单，在服务端实现也非常简单，只需简单配置apache等web服务器即可实现，所以对于简单的服务来说还是挺方便的。 但是这种方式安全性较低，就是简单的将用户名和密码base64编码放到header中: base64编码前：Basic admin:admin base64编码后：Basic YWRtaW46YWRtaW4= 放到Header中：Authorization: Basic YWRtaW46YWRtaW4= 正是因为是简单的base64编码存储，切记切记在这种方式下一定得注意使用ssl，不然就是裸奔了。 在某些产品中也是基于这种类似方式，只是没有使用apache的basic机制，而是自己写了认证框架，原理还是一样的，在一次请求中base64解码Authorization字段，再和认证信息做校验。 很显然这种方式有问题，认证信息相当于明文传输，另外也没有防暴力破解功能。2.API KEY API Key就是经过用户身份认证之后服务端给客户端分配一个API Key, 类似: http://example.com/api?key=dfkaj134, 一般的处理流程(一个简单的设计示例)如下: client端: server端: 分析:client端向服务端注册,服务端把相应的api_key以及security_key给客户端,注意保存不要泄露;然后客户端根据api_key,secrity_key,timestrap,rest_uri采用hmacsha256算法得到一个hash值sign,构造途中的url发送给服务端;服务端收到该请求后,首先验证api_key是否存在,存在则获取该api_key的security_key;接着验证timestrap是否超过时间限制,可依据系统成而定,这样就防止了部分重放攻击(后面还会有更好的解决重放的方案);图中的rest_api是从url获取的,为/rest/v1/interface/eth0 ;最后计算sign值,完之后和url中的sign值做校验,这样的设计就防止了数据被篡改;通过这种API Key的设计方式加了时间戳防止了部分重放,加了校验,防止了数据被篡改,同时避免了传输用户名和密码,当然了也会有一定的开销。 Oauth1.0a或者Oauth2OAuth协议适用于为外部应用授权访问本站资源的情况。其中的加密机制与HTTP Digest身份认证相比，安全性更高。使用和配置都比较复杂，这里就不涉及了。 JWTJWT 是JSON Web Token，用于发送可通过数字签名和认证的东西，它包含一个紧凑的，URL安全的JSON对象，服务端可通过解析该值来验证是否有操作权限，是否过期等安全性检查。由于其紧凑的特点，可放在url中或者 HTTP Authorization头中，具体的算法就如下图: 参考:理解RESTful架构RESTful API设计指南","tags":[{"name":"RESTful","slug":"RESTful","permalink":"http://blog.renyimin.com/tags/RESTful/"}]},{"title":"05-Go变量类型","date":"2017-03-28T14:15:09.000Z","path":"2017/03/28/2017-03-28-go-05/","text":"一.基础类型1.布尔类型: bool2.整型: int8, byte, int16, int32, int64, unint8, unint16, unint32, unint64, int, uint, uintptrint,uint,uintptr 是基于架构的类型,这些类型的长度都是根据运行程序所在的操作系统类型所决定的; int和uint在32位操作系统上,它们均使用32位(4个字节), 在64位操作系统上, 它们均使用64位(8个字节); uintptr的长度被设定为足够存放一个指针即可; //TODO 与操作系统架构无关的类型都有固定的大小,并在类型的名称中就可以看出来: 整数: int8（-128-&gt;127） int16（-32768-&gt;32767） int32（-2,147,483,648-&gt;2,147,483,647） int64（-9,223,372,036,854,775,808-&gt;9,223,372,036,854,775,807） uint8（0-&gt;255） uint16（0-&gt;65,535） uint32（0-&gt;4,294,967,295） uint64（0-&gt;18,446,744,073,709,551,615） int 型是计算最快的一种类型 3.浮点类型: float32, float64 浮点型（IEEE-754标准）Go语言中没有float类型 float32（+-1e-45 -&gt; +-3.4*1e38） float64（+-51e-324 -&gt; 107 1e308） float32精确到小数点后7位,float64精确到小数点后15位。 由于精确度的缘故,你在使用==或者!=来比较浮点数时应当非常小心,你最好在正式使用前测试对于精确度要求较高的运算。 你应该 尽可能地使用float64 ，因为math包中所有有关数学运算的函数都会要求接收这个类型。 4.复数类型: complex64, complex128//TODO 5.字符串: string//TODO- 字符串拼接符+ 在循环中使用加号+拼接字符串并不是最高效的做法，更好的办法是使用函数strings.Join() 使用字节缓冲(bytes.Buffer)拼接更加给力 6.字符类型: rune//TODO 7.错误类型: error二.复合类型1.指针(pointer)指针对于性能的影响是不言而喻的,而如果你想要做的是系统编程、操作系统或者网络应用,指针更是不可或缺的一部分;Go语言的取地址符是&amp;, 放到一个变量前使用就会返回相应变量的内存地址;当一个指针被定义后没有分配到任何变量时,它的值为nil;对一个空指针的反向引用是不合法的，并且会使程序崩溃; 2.数组(array)数组是具有相同唯一类型的一组已编号且长度固定的数据项序列（这是一种同构的数据结构）:这种类型可以是任意的原始类型例如整形、字符串或者自定义类型; 数组长度也是数组类型的一部分，所以[5]int和[10]int是属于不同类型的; 注意事项如果我们想让数组元素类型为任意类型的话可以使用空接口作为类型; 使用值时,必须先做一个类型判断; 3.切片(slice)4.字典(map)5.通道(chan)6.结构体(struct)7.接口(interface)","tags":[{"name":"go","slug":"go","permalink":"http://blog.renyimin.com/tags/go/"}]},{"title":"10-RabbitMQ中实现RPC机制","date":"2017-03-28T14:10:07.000Z","path":"2017/03/28/2017-03-28-rabbitmq-10-rpc/","text":"1.RPC MQ本身是基于异步的消息处理,前面的示例中所有的生产者（P）将消息发送到RabbitMQ后不会知道消费者（C）处理成功或者失败（甚至连有没有消费者来处理这条消息都不知道）; 但实际的应用场景中，我们很可能需要一些同步处理，需要同步等待服务端将我的消息处理完成后再进行下一步处理。这相当于RPC（Remote Procedure Call，远程过程调用）; 在RabbitMQ中也支持RPC。 RabbitMQ中实现RPC的机制是:1.客户端发送请求（消息）时,在消息的属性（MessageProperties，在AMQP协议中定义了14种properties，这些属性会随着消息一起发送）中设置两个值replyTo（Queue名称，用于告诉服务器处理完成后将通知我的消息发送到这个Queue中）和 correlationId（此次请求的标识号，服务器处理完成后需要将此属性返还，客户端将根据这个id了解哪条请求被成功执行了或执行失败）;2.服务器端收到消息并处理 服务器端处理完消息后,将生成一条应答消息到replyTo指定的Queue,同时带上correlationId属性; 客户端之前已订阅replyTo指定的Queue,从中收到服务器的应答消息后,根据其中的correlationId属性分析哪条请求被执行了,根据执行结果进行后续业务处理;3.代码:生产者:123456789101112131415161718192021222324252627282930313233343536public function publisher(Request $request)&#123; $msg = 'hello World'; // 路由名称 $exchange = 'testRouter'; // 队列名称 $queue_name1 = 'queue1'; // 回执队列名称 $reply_to_queue = 'queue2'; // 连接RabbitMQ服务 $connection = new AMQPStreamConnection('localhost', '5672', 'guest', 'guest'); // 创建信道 $channel = $connection-&gt;channel(); // 声明一个路由 $channel-&gt;exchange_declare($exchange, 'direct', false, true, false); // 声明队列 // 需要先在队列中声明队列所支持的最大优先级 $channel-&gt;queue_declare($queue_name1, false, true, false, false, false, new AMQPTable(array(\"x-max-priority\" =&gt; 20))); // rpc的回执队列 $channel-&gt;queue_declare($reply_to_queue, false, true, false, false, false, new AMQPTable(array(\"x-max-priority\" =&gt; 30))); // 绑定路由和队列 $channel-&gt;queue_bind($queue_name1, $exchange, 'bindingKey1'); // 创建消息 $messageBody = $msg; // rpc测试 $message = new AMQPMessage($messageBody, array('content_type' =&gt; 'text/plain', 'delivery_mode' =&gt; AMQPMessage::DELIVERY_MODE_PERSISTENT, 'priority'=&gt;'10', 'reply_to'=&gt;$reply_to_queue, 'correlation_id'=&gt;'testId')); $channel-&gt;basic_publish($message, $exchange, 'bindingKey1'); $channel-&gt;close(); $connection-&gt;close();&#125; 消费者:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566&lt;?phpnamespace App\\Console\\Commands;use Illuminate\\Console\\Command;use Illuminate\\Contracts\\Logging\\Log;use PhpAmqpLib\\Connection\\AMQPStreamConnection;use PhpAmqpLib\\Message\\AMQPMessage;class Consumer extends Command&#123; /** * The name and signature of the console command. * * @var string */ protected $signature = 'Consumer'; /** * The console command description. * * @var string */ protected $description = '测试消费者'; public function __construct() &#123; parent::__construct(); &#125; /** * Execute the console command. * * @return mixed */ public function handle() &#123; // 队列名称 $queue = 'queue1'; // 消费者tag $consumerTag = 'consumer'; // 连接RabbitMQ服务 $connection = new AMQPStreamConnection('localhost', '5672', 'guest', 'guest'); // 创建信道 $channel = $connection-&gt;channel(); $backCall = function ($req) &#123; echo \"\\n--------\\n\"; \\Illuminate\\Support\\Facades\\Log::info(123); echo $req-&gt;body; echo \"\\n--------\\n\"; $msg = new AMQPMessage( $req-&gt;body, array('correlation_id' =&gt; $req-&gt;get('correlation_id')) ); $req-&gt;delivery_info['channel']-&gt;basic_publish($msg, '', $req-&gt;get('reply_to')); $req-&gt;delivery_info['channel']-&gt;basic_ack($req-&gt;delivery_info['delivery_tag']); &#125;; $channel-&gt;basic_consume($queue, $consumerTag, false, false, false, false, $backCall); while (count($channel-&gt;callbacks)) &#123; $channel-&gt;wait(); &#125; &#125;&#125; 参考: http://www.rabbitmq.com/tutorials/tutorial-six-php.html","tags":[{"name":"rabbitmq","slug":"rabbitmq","permalink":"http://blog.renyimin.com/tags/rabbitmq/"},{"name":"php","slug":"php","permalink":"http://blog.renyimin.com/tags/php/"}]},{"title":"09-过期队列,消息","date":"2017-03-27T14:00:14.000Z","path":"2017/03/27/2017-03-27-rabbitmq-09/","text":"1.队列使用过的属性: x-max-priority: 设置队列中所推送的消息最大优先级数字 x-expires: 设置队列过期时间 (expiration:用来设置队列中某条消息的过期时间; 队列上设置消息过期时间和消息上设置消息过期时间,优先级以较小的时间为准 ) 设置消息过期,也可以不用设置队列过期时间 2.代码:生产者:1234567891011121314151617181920212223242526272829303132333435public function publisher(Request $request)&#123; $msg = 'hello World'; // 路由名称 $exchange = 'testRouter'; // 队列名称 $queue_name1 = 'queue1'; // 回执队列名称 $reply_to_queue = 'queue2'; // 连接RabbitMQ服务 $connection = new AMQPStreamConnection('localhost', '5672', 'guest', 'guest'); // 创建信道 $channel = $connection-&gt;channel(); // 声明一个路由 $channel-&gt;exchange_declare($exchange, 'direct', false, true, false); // 队列在超过50秒后就会删除 $channel-&gt;queue_declare($queue_name1, false, true, false, false, false, new AMQPTable(array(\"x-max-priority\" =&gt; 20,'x-expires'=&gt;50000))); // 队列在超过10秒后就会删除 $channel-&gt;queue_declare($reply_to_queue, false, true, false, false, false, new AMQPTable(array(\"x-max-priority\" =&gt; 30,'x-expires'=&gt;10000))); // 绑定路由和队列 $channel-&gt;queue_bind($queue_name1, $exchange, 'bindingKey1'); // 创建消息 $messageBody = $msg; // rpc测试 $message = new AMQPMessage($messageBody, array('content_type' =&gt; 'text/plain', 'delivery_mode' =&gt; AMQPMessage::DELIVERY_MODE_PERSISTENT, 'priority'=&gt;'10', 'reply_to'=&gt;$reply_to_queue, 'correlation_id'=&gt;'testId')); $channel-&gt;basic_publish($message, $exchange, 'bindingKey1'); $channel-&gt;close(); $connection-&gt;close();&#125;","tags":[{"name":"rabbitmq","slug":"rabbitmq","permalink":"http://blog.renyimin.com/tags/rabbitmq/"},{"name":"php","slug":"php","permalink":"http://blog.renyimin.com/tags/php/"}]},{"title":"04-Go基本命令","date":"2017-03-27T13:30:21.000Z","path":"2017/03/27/2017-03-27-go-04/","text":"一.环境变量windows下使用msi安装包安装go的话, 会自动配置环境变量GOROOT, 并且在PATH中配置go安装目录下的bin目录,可以使用go env命令查看: 如果要开始go项目开发,我们只需要做的就是配置一下GOPATH环境变量(为项目所在目录)即可; (后面细讲) 二.基本命令1.go get: 获取远程包(需提前安装 git 或 hg) 2.go run: 直接运行程序go run 不需要设置环境变量GOPATH的,需要到源码目录中执行, 并且命令后面跟所要运行的源码文件(注意只能用于main包(即main函数文件),否则会出现 go run: cannot run non-main package 的错误;); 执行go run命令会直接运行.go源码文件, 貌似不会产生可执行文件; 3.go build: 测试编译,检查是否有编译错误只是对源码文件进行编译, 而且只能编译main, 并且不会有程序运行结果; 在一般情况下, go build命令后面需要加上要编译的Go源文件名, 默认情况下得到的可执行文件的名字为源文件名字去掉.go后缀; 之所以说在一般情况下, 是因为go build命令也可以main包目录里直接运行(此时就不需要写Go原文件名了, 前提是src目录下只有一个main包这么一个源码文件), 会在运行的当前目录下生成main包所在目录.exe文件,当然一般不这么用; 4.go fmt: 格式化源码(部分IDE在保存时会自动调用) 5.go install: 编译包文件并编译整个程序go install 命令必须设置 GOPATH 环境变量; go install 命令会编译包, 并同时复制结果到$GOPATH/bin，$GOPATH/pkg等对应目录下; 注意: go install 是针对package, 而不是针对单个.go文件; 注意: 该命令并不像网上一些文章说的那样必需要设置GOBIN环境变量, 当GOBIN环境变量为空时, package main的main函数文件不能直接放到GOPATH的src下面, 如果main函数文件直接放在GOPATH的src下面,则会如下:如果不设置GOBIN的话, 注意: 此时package main的main函数文件不能直接放到GOPATH的src下面, 而是在src下建立項目目录即可; 如果此时设置了GOBIN环境变量,那就可以编译包, 并同时复制结果到$GOPATH/bin，$GOPATH/pkg等对应目录下;(一般就不设置GOBIN环境变量了) go test: 运行测试文件go doc: 查看文档6.go的这些命令这里只是点到为止,继续深入请查看手册;","tags":[{"name":"go","slug":"go","permalink":"http://blog.renyimin.com/tags/go/"}]},{"title":"03-Go目录结构","date":"2017-03-26T01:15:13.000Z","path":"2017/03/26/2017-03-26-go-03/","text":"目录结构1.项目目录结构如何组织，一般语言都是没有规定。但Go语言这方面做了规定,这样可以保持一致性,做到统一, 规则化比较明确; 2.一般的,一个Go项目的目录下会有如下三个目录: |--bin |--pkg |--src bin:存放编译后的可执行文件;pkg:存放编译后的包文件;src:存放项目源文件; 注意:一般bin, pkg两个目录可以不创建,go命令(go install命令)会自动去创建这两个目录, 前提是已经配置好了GOPATH环境变量为项目目录了, 并且项目源码文件不是直接放置在src目录下的 ;","tags":[{"name":"go","slug":"go","permalink":"http://blog.renyimin.com/tags/go/"}]},{"title":"02-Go环境安装","date":"2017-03-25T15:10:09.000Z","path":"2017/03/25/2017-03-25-go-02/","text":"1.windows下载","tags":[{"name":"go","slug":"go","permalink":"http://blog.renyimin.com/tags/go/"}]},{"title":"01-认识Go语言","date":"2017-03-25T14:20:14.000Z","path":"2017/03/25/2017-03-25-go-01/","text":"Go语言的 起源与发展Go语言起源2007年,并于2009年正式对外发布; 它从2009年9月21日开始作为谷歌公司20%兼职项目,即相关员工利用20%的空余时间来参与Go语言的研发工作; 该项目的三位领导者均是著名的IT工程师: Robert Griesemer (参与开发Java HotSpot虚拟机) Rob Pike, Go语言项目总负责人,贝尔实验室Unix团队成员,参与的项目包括Plan9,Inferno操作系统和Limbo编程语言; Ken Thompson,贝尔实验室Unix团队成员,C语言、Unix和Plan9的创始人之一,与Rob Pike共同开发了UTF-8字符集规范; 这是一个由计算机领域”发明之父”所组成的黄金团队,他们对系统编程语言,操作系统和并行都有着非常深刻的见解; 时间轴:2007年9月21日: 雏形设计2009年11月10日: 首次公开发布2010年1月8日: 当选2009年年度语言2010年5月: 谷歌投入使用2011年5月5日: Google App Engine支持Go语言 Go语言的官方网站是https://golang.org/, 这个站点采用Python作为前端,并且使用Go语言自带的工具godoc运行在Google App Engine上来作为Web服务器提供文本内容。在官网的首页有一个功能叫做Go Playground, 是一个Go代码的简单编辑器的沙盒,它可以在没有安装Go语言的情况下在你的浏览器中编译并运行Go; Go通过以下的Logo来展示它的速度,并以囊地鼠（Gopher）作为它的吉祥物: 在Go语言出现之前，开发者们总是面临非常艰难的抉择，究竟是使用执行速度快但是编译速度并不理想的语言（如：C++），还是使用编译速度较快但执行效率不佳的语言（如：.NET、Java），或者说开发难度较低但执行速度一般的动态语言呢？显然，Go语言在这3个条件之间做到了最佳的平衡:快速编译，高效执行，易于开发。 Go语言特色 (体验到了就补充) 参考:http://studygolang.com/articles/2959","tags":[{"name":"go","slug":"go","permalink":"http://blog.renyimin.com/tags/go/"}]},{"title":"08-优先级队列","date":"2017-03-25T13:20:14.000Z","path":"2017/03/25/2017-03-25-rabbitmq-08/","text":"1.RabbitMQ在版本3.5.0的核心中具有了优先级队列的实现。注意: 只有当消费者不足, 不能及时进行消费的情况下, 优先级队列才会生效 ; 2.您可以使用x-max-priority参数声明优先级队列,该参数应该是一个整数,表示队列应该支持的最大优先级。消息的优先级如果超过了队列所设置的消息最大优先级, 在消费者不足的时候, 优先级貌似也还是失效的; 代码(生产者): 12345678910111213141516171819202122232425262728293031323334public function publisher(Request $request)&#123; $msg = 'hello World'; // 路由名称 $exchange = 'testRouter'; // 队列名称 $queue_name1 = 'queue1'; // 连接RabbitMQ服务 $connection = new AMQPStreamConnection('localhost', '5672', 'guest', 'guest'); // 创建信道 $channel = $connection-&gt;channel(); // 声明一个路由 $channel-&gt;exchange_declare($exchange, 'direct', false, true, false); // 声明队列 // 需要先在队列中声明队列所支持的最大优先级(这里设置为20) $channel-&gt;queue_declare($queue_name1, false, true, false, false, false, new AMQPTable(array(\"x-max-priority\" =&gt; 20))); // 绑定路由和队列 $channel-&gt;queue_bind($queue_name1, $exchange, 'bindingKey1'); // 创建消息 $messageBody = $msg; // 设置队列中消息的优先级 $message = new AMQPMessage($messageBody, array('content_type' =&gt; 'text/plain', 'delivery_mode' =&gt; AMQPMessage::DELIVERY_MODE_PERSISTENT, 'priority'=&gt;'15')); $channel-&gt;basic_publish($message, $exchange, 'bindingKey1'); $message1 = new AMQPMessage('sssss', array('content_type' =&gt; 'text/plain', 'delivery_mode' =&gt; AMQPMessage::DELIVERY_MODE_PERSISTENT, 'priority'=&gt;'20')); $channel-&gt;basic_publish($message1, $exchange, 'bindingKey1'); $channel-&gt;close(); $connection-&gt;close();&#125; 3.注意 (如上述第一点所说): 如果先启动消费者, 然后生产者发送两条消息, 此时消息并不会按照优先级进行消费, 因为消费者足够消费队列中的消息, 所以并不会判断优先级; 如果先发送两条消息, 然后再启动消费者, 此时就会按照优先级进行消费 (这种情况相当于消费者不足, 增加了新的消费者); 创建一个同名队列, 如果其他参数不同(比如消息的最大优先级数字设置不同), 则会报错 ;","tags":[{"name":"rabbitmq","slug":"rabbitmq","permalink":"http://blog.renyimin.com/tags/rabbitmq/"},{"name":"php","slug":"php","permalink":"http://blog.renyimin.com/tags/php/"}]},{"title":"05-AMQP消息属性,持久化,事务","date":"2017-03-20T04:40:14.000Z","path":"2017/03/20/2017-03-20-rabbitmq-05/","text":"Message properties（消息属性）AMQP协议预定义了14个消息属性。大部分属性都很少用到, 下面的除外: delivery_mode: 设置为2表示持久化, 1为临时的。 content_type: 用来表述编码mime-type, 例如常用的JSON编码, 良好的做法是设置这个属性为: application/json (git上的例子也用了text/plain) reply_to: 常用作回调队列名 correlation_id: 用来关联RPC的请求与响应 expiration: 设置队列中具体某条消息的过期时间 (x-expires设置队列过期时间) priority: 消息的优先级(也不常用,主要是消费者不够的时候才会体现出来) x-dead-letter-exchange: 过期消息转向路由 x-dead-letter-routing-key: 过期消息转向路由相匹配routingkey (一般和上一个属性一起用) 持久化1.RabbitMQ 默认是非持久 队列 、 Exchange 、 消息 的,这意味着一旦消息服务器重启, 所有已声明的队列, Exchange 以及队列中的消息都会丢失。 通过设置Exchange和MessageQueue的durable属性为true,可以使得队列和Exchange持久化; 但是这还不能使得队列中的消息持久化,这需要生产者在发送消息的时候,将delivery mode设置为2,只有这3个全部设置完成后,才能保证服务器重启不会对现有的队列造成影响。 这里需要注意的是, 只有 durable为true的Exchange 和 durable为ture的Queues 才能绑定, 否则在绑定时, RabbitMQ都会抛错的。 持久化会对RabbitMQ的性能造成比较大的影响, 可能会下降10倍不止。 事务机制 VS Publisher Confirm1.在使用RabbitMQ的时候，我们可以通过消息持久化操作来解决因为服务器的异常奔溃导致的消息丢失，除此之外我们还会遇到一个问题，当消息的发布者在将消息发送出去之后，消息到底有没有正确到达broker代理服务器呢？如果不进行特殊配置的话，默认情况下发布操作是不会返回任何信息给生产者的，也就是默认情况下我们的生产者是不知道消息有没有正确到达broker的，如果在消息到达broker之前已经丢失的话，持久化操作也解决不了这个问题，因为消息根本就没到达代理服务器，你怎么进行持久化，那么这个问题该怎么解决呢？ 2.RabbitMQ为我们提供了两种方式: 方式一:通过AMQP事务机制实现，这也是从AMQP协议层面提供的解决方案; 方式二:通过将channel设置成confirm模式来实现; AMQP事务机制实现1.首先,通过实例来看看AMQP的事务模式是怎么使用的: RabbitMQ中与事务机制有关的方法有三个,分别是Channel里面的txSelect(),txCommit()以及txRollback(); txSelect用于将当前Channel设置成是transaction模式; txCommit用于提交事务; txRollback用于回滚事务; 在通过txSelect开启事务之后,我们便可以发布消息给broker代理服务器了,如果txCommit提交成功了,则消息一定是到达broker了,如果在txCommit执行之前broker异常奔溃或者由于其他原因抛出异常,这个时候我们便可以捕获异常通过txRollback回滚事务了; 2.代码:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public function publisher(Request $request)&#123; // 路由名称 $exchange = 'testRouter'; // 队列名称 $queue_name1 = 'queue1'; // 连接RabbitMQ服务 $connection = new AMQPStreamConnection('localhost', '5672', 'guest', 'guest'); // 创建信道 $channel = $connection-&gt;channel(); // 声明一个路由 $channel-&gt;exchange_declare($exchange, 'direct', false, true, false); // 声明队列 // 需要先在队列中声明队列所支持的最大优先级 $channel-&gt;queue_declare($queue_name1, false, true, false, false, false, new AMQPTable(array(\"x-max-priority\" =&gt; 20))); $channel-&gt;queue_bind($queue_name1, $exchange, 'bindingKey1'); try &#123; //开启事务 $channel-&gt;tx_select(); for( $i = 0; $i &lt; 10; $i++) &#123; $message = new AMQPMessage( 'tests' . $i, array( 'content_type' =&gt; 'text/plain', 'delivery_mode' =&gt; AMQPMessage::DELIVERY_MODE_PERSISTENT, )); $channel-&gt;basic_publish($message, $exchange, 'bindingKey1'); // 模拟事务失败的情况 /*if($i == 2) &#123; $result = 1/0; &#125;*/ &#125; //提交事务 $channel-&gt;tx_commit(); &#125; catch (\\Exception $e) &#123; $channel-&gt;tx_rollback(); &#125; $channel-&gt;close(); $connection-&gt;close();&#125;// 可以发现, 在模拟事务失败的情况下, 之前的两条消息也都会被回滚, 队列中消息是0条 3.使用事务确实能够解决发布者与broker代理服务器之间的消息确认，只有消息成功被broker接收事务提交才能成功，否则我们便可以在捕获异常进行事务回滚操作同时进行消息重发，但是使用事务机制的话会降低RabbitMQ的性能，就拿上面的程序发送1000条消息，使用事务的话需要58244毫秒，而不使用事务的话仅仅需要89毫秒，因此在实际中使用事务会带来很大的性能损失，那么有没有更好的方法既能保证发布者知道消息已经正确到达，又能基本上不带来性能上的损失呢？从AMQP协议的层面看是没有更好的方法的，但是RabbitMQ提供了一个更好的方案，即将channel信道设置成confirm模式; 将channel设置成confirm模式1.生产者确认模式实现原理: 生产者将信道设置成confirm模式,一旦信道进入confirm模式,所有在该信道上面发布的消息都将会被指派一个唯一的ID(从1开始),一旦消息被投递到所有匹配的队列之后,broker就会发送一个确认给生产者(包含消息的唯一ID),这就使得生产者知道消息已经正确到达目的队列了,如果消息和队列是可持久化的,那么确认消息会在将消息写入磁盘之后发出,broker回传给生产者的确认消息中delivery-tag域包含了确认消息的序列号,此外broker也可以设置basic.ack的multiple域,表示到这个序列号之前的所有消息都已经得到了处理; confirm模式最大的好处在于他是异步的,一旦发布一条消息,生产者应用程序就可以在等信道返回确认的同时继续发送下一条消息,当消息最终得到确认之后,生产者应用便可以通过回调方法来处理该确认消息,如果RabbitMQ因为自身内部错误导致消息丢失,就会发送一条nack消息,生产者应用程序同样可以在回调方法中处理该nack消息; 2.开启confirm模式的方法: 生产者通过调用channel的confirmSelect方法将channel设置为confirm模式; 注意一点,已经在transaction事务模式的channel是不能再设置成confirm模式的,即这两种模式是不能共存的,如果没有设置no-wait标志的话,broker会返回confirm.select-ok表示同意发送者将当前channel信道设置为confirm模式(从目前RabbitMQ最新版本3.6来看,如果调用了channel.confirmSelect方法,默认情况下是直接将no-wait设置成false的,也就是默认情况下broker是必须回传confirm.select-ok的,而且我也没找到我们自己能够设置no-wait标志的方法); 3.生产者实现confirm模式有两种编程方式: 普通confirm模式,每发送一条消息,调用waitForConfirms()方法等待服务端confirm,这实际上是一种串行的confirm，每publish一条消息之后就等待服务端confirm,如果服务端返回false或者超时时间内未返回,客户端进行消息重传; 批量confirm模式,每发送一批消息之后,调用waitForConfirms()方法,等待服务端confirm,这种批量确认的模式极大的提高了confirm效率,但是如果一旦出现confirm返回false或者超时的情况,客户端需要将这一批次的消息全部重发,这会带来明显的重复消息,如果这种情况频繁发生的话,效率也会不升反降; 4.基本的原理之后,代码级别我们该怎么设置channel信道为confirm模式呢?以及我们该怎么获取broker返回给我们的确认消息呢？ 参考:http://blog.csdn.net/hzw19920329/article/details/54340711","tags":[{"name":"rabbitmq","slug":"rabbitmq","permalink":"http://blog.renyimin.com/tags/rabbitmq/"},{"name":"php","slug":"php","permalink":"http://blog.renyimin.com/tags/php/"}]},{"title":"04-队列基本属性","date":"2017-03-19T13:20:45.000Z","path":"2017/03/19/2017-03-19-rabbitmq-04/","text":"注意: 同一vhost下, 声明同名队列, 如果参数不同, 则会报错 !如: 1.durable设置为true, 表示声明的队列为持久队列; 注意: 注意的是, 只有 durable为true的Exchange 和 durable为ture的Queues 才能绑定, 否则在绑定时, RabbitMQ都会抛错的2.passive: 检测是否已存在队列,存在则成功返回; 否则不创建队列且返回一个错误。 Exclusive：1.排他队列是基于连接可见的，同一连接的不同信道是可以同时访问同一个连接创建的排他队列的;2.”首次”，如果一个连接已经声明了一个排他队列，其他连接是不允许建立同名的排他队列的，这个与普通队列不同;3.即使该排他队列是持久化的,一旦连接关闭或者客户端退出, 该排他队列都会被自动删除的; 4.当需要将队列限制在只有一个消费者时,这很有用 (参考): 由于生产者和消费者在创建队列的时候使用的是不同的连接, 所以, 如果两次创建exclusive队列的话, 会报错; 如果在生产者中创建exclusive队列的话, 在运行生产者的时候,由于没有绑定消费者,所以队列不会被创建,导致之后在绑定消费者的时候, 由于队列不存在,所以也绑定不上 ; 因此可以在消费者中创建exclusive队列, 这样, 在运行生产者的时候, 不用创建队列直接发送消息即可, 注意, 消费者进程一断, 队列就被删除了 ; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788// 如下:排他队列由消费者创建, 生产者只用发送消息, 队列只能是这一个消费者//生产者public function publisher(Request $request)&#123; $exchange = 'testRouter'; // 连接RabbitMQ服务 $connection = new AMQPStreamConnection('localhost', '5672', 'guest', 'guest'); // 创建信道 $channel = $connection-&gt;channel(); $message = new AMQPMessage( 'tests', array( 'content_type' =&gt; 'text/plain', 'delivery_mode' =&gt; AMQPMessage::DELIVERY_MODE_PERSISTENT, ) ); $channel-&gt;basic_publish($message, $exchange, 'bindingKey1'); $channel-&gt;close(); $connection-&gt;close();&#125;//消费者&lt;?phpnamespace App\\Console\\Commands;use Illuminate\\Console\\Command;use Illuminate\\Contracts\\Logging\\Log;use PhpAmqpLib\\Connection\\AMQPStreamConnection;use PhpAmqpLib\\Message\\AMQPMessage;class Consumer extends Command&#123; /** * The name and signature of the console command. * * @var string */ protected $signature = 'Consumer'; /** * The console command description. * * @var string */ protected $description = '测试消费者'; public function __construct() &#123; parent::__construct(); &#125; /** * Execute the console command. * * @return mixed */ public function handle() &#123; $exchange = 'testRouter'; // 队列名称 $queue = 'queue1'; // 消费者tag $consumerTag = 'consumer'; // 连接RabbitMQ服务 $connection = new AMQPStreamConnection('localhost', '5672', 'guest', 'guest'); // 创建信道 $channel = $connection-&gt;channel(); // 声明一个路由 $channel-&gt;exchange_declare($exchange, 'direct', false, true, false); // 创建队列 (设置为持久, 排他队列) $channel-&gt;queue_declare($queue, false, true, true, false, false); // 绑定路由和队列 $channel-&gt;queue_bind($queue, $exchange, 'bindingKey1'); $backCall = function ($req) &#123; echo \"\\n--------\\n\"; echo $req-&gt;body; echo \"\\n--------\\n\"; $req-&gt;delivery_info['channel']-&gt;basic_ack($req-&gt;delivery_info['delivery_tag']); &#125;; $channel-&gt;basic_consume($queue, $consumerTag, true, false, false, false, $backCall); while (count($channel-&gt;callbacks)) &#123; $channel-&gt;wait(); &#125; &#125;&#125; auto-delete当最后一个消费者取消订阅时,队列将被自动删除;","tags":[{"name":"rabbitmq","slug":"rabbitmq","permalink":"http://blog.renyimin.com/tags/rabbitmq/"},{"name":"php","slug":"php","permalink":"http://blog.renyimin.com/tags/php/"}]},{"title":"03-Exchange Types","date":"2017-03-18T14:10:19.000Z","path":"2017/03/18/2017-03-18-rabbitmq-03/","text":"1.RabbitMQ常用的Exchange Type有fanout、direct、topic、headers这四种(不过headers类型并不太实用,而且性能比较差,几乎再也用不到了),下面分别介绍前三种Exchange: fanout: fanout类型的Exchange路由规则非常简单, 它会把所有发送到该Exchange的消息路由到所有与它绑定的Queue中 ; direct: direct类型的Exchange路由规则也很简单，它会把消息路由到那些Binding key与Routing key完全匹配的Queue中。 topic: 前面讲到direct类型的Exchange路由规则是完全匹配binding key与routing key，但这种严格的匹配方式在很多情况下不能满足实际业务需求。topic类型的Exchange在匹配规则上进行了扩展，它与direct类型的Exchage相似，也是将消息路由到binding key与routing key相匹配的Queue中，但这里的匹配规则有些不同，它约定： routing key为一个句点号“. ”分隔的字符串（我们将被句点号“. ”分隔开的每一段独立的字符串称为一个单词），如“stock.usd.nyse”、“nyse.vmw”、“quick.orange.rabbit” binding key与routing key一样也是句点号“. ”分隔的字符串 binding key中可以存在两种特殊字符“”与“#”，用于做模糊匹配，其中“”用于匹配一个单词，“#”用于匹配多个单词（可以是零个） Direct类型的Exchange :1.Direct类型的交换机在 消息发送到队列过程中 所使用的路由规则比较严格 ! 注意: 如果不创建交换机, 则RabbitMQ默认会使用一个direct类型的交换机, 并且, 发送消息的时候, 需要指定routingKey和创建queue时的queue_name一致, 因为如果不声明路由,即使用默认路由的话, RabbitMQ会把队列的queue_name作为队列和那个默认direct类型交换器绑定的bindingKey, 否则消息就不能正确路由到队列中而丢失。 代码: 12345678910111213141516171819202122232425262728public function publisher()&#123; // 队列名称 $queue_name = 'queue1'; // 连接RabbitMQ服务 $connection = new AMQPStreamConnection('localhost', '5672', 'guest', 'guest'); // 创建信道 $channel = $connection-&gt;channel(); // 不创建Exchange // 默认会使用一个direct类型的xchange // 声明队列 $channel-&gt;queue_declare($queue_name , false, true, false, false); // 因为没有明确声明的Exchange, 所以也不需要让队列去绑定默认的交换器 // 创建消息 $messageBody = 'we are family'; $message = new AMQPMessage($messageBody, array('content_type' =&gt; 'text/plain', 'delivery_mode' =&gt; AMQPMessage::DELIVERY_MODE_PERSISTENT)); // 此时, 要发送消息到创建的队列中的话, 此处的routingKey需要和队列名相同 $channel-&gt;basic_publish($message, '', $queue_name); $channel-&gt;close(); $connection-&gt;close();&#125; 2.使用direct类型的Exchange测试 : 多个队列使用完全相同的bindingKey绑定同一个Exchange, 并且发送消息时的routingKey和bindingKey相同, 此时, 消息会发送到其中某个队列? 还是每个队列都会发送消息 ? 每个队列都会收到该消息 代码 : 12345678910111213141516171819202122232425262728293031323334353637public function publisher()&#123; // 路由名称 $exchange = 'testRouter'; // 队列名称 $queue_name1 = 'queue1'; $queue_name2 = 'queue2'; $queue_name3 = 'queue3'; // 连接RabbitMQ服务 $connection = new AMQPStreamConnection('localhost', '5672', 'guest', 'guest'); // 创建信道 $channel = $connection-&gt;channel(); // 声明一个路由 (direct类型, 也可以不用自己声明, 默认使用的也是一个direct类型的Exchange) $channel-&gt;exchange_declare($exchange, 'direct', false, true, false); // 声明3个队列 (参数暂时不用了解) $channel-&gt;queue_declare($queue_name1, false, true, false, false); $channel-&gt;queue_declare($queue_name2, false, true, false, false); $channel-&gt;queue_declare($queue_name3, false, true, false, false); // 绑定路由和队列 $channel-&gt;queue_bind($queue_name1, $exchange, 'bindingKey1'); $channel-&gt;queue_bind($queue_name2, $exchange, 'bindingKey1'); $channel-&gt;queue_bind($queue_name3, $exchange, 'bindingKey1'); // 创建消息 $messageBody = '12345'; $message = new AMQPMessage($messageBody, array('content_type' =&gt; 'text/plain', 'delivery_mode' =&gt; AMQPMessage::DELIVERY_MODE_PERSISTENT)); // 发布消息 (这里,生产者在发布消息的时候,这个 routingKey 和 队列与交换器绑定的bindingKey必须一致 ) $channel-&gt;basic_publish($message, $exchange, 'bindingKey1'); $channel-&gt;close(); $connection-&gt;close();&#125; 此时由于没有启动消费者进程, 所以消息会一直在队列中等待消费者来订阅并进行消费 ; 3.多个队列使用不完全相同的bindingKey绑定同一个Exchange, 并且发送消息时的routingKey和其中某些bindingKey相同, 此时: 只会发送到routingKey和bindingKey相同的队列 对于routingKey和bindingKey不同的, 队列中是不会收到消息的; 所以如果只有一个队列, 并且bindingKey和发送消息时的routingKey不一样, 那消息就彻底丢失了 代码 : 1234567891011121314151617181920212223242526272829303132333435public function publisher()&#123; // 路由名称 $exchange = 'testRouter'; // 队列名称 $queue_name1 = 'queue1'; $queue_name2 = 'queue2'; $queue_name3 = 'queue3'; // 连接RabbitMQ服务 $connection = new AMQPStreamConnection('localhost', '5672', 'guest', 'guest'); // 创建信道 $channel = $connection-&gt;channel(); // 声明一个路由 (direct类型) $channel-&gt;exchange_declare($exchange, 'direct', false, true, false); // 声明队列 (参数暂时不用了解) $channel-&gt;queue_declare($queue_name1, false, true, false, false); $channel-&gt;queue_declare($queue_name2, false, true, false, false); $channel-&gt;queue_declare($queue_name3, false, true, false, false); // 绑定路由和队列 $channel-&gt;queue_bind($queue_name1, $exchange, 'bindingKey1'); $channel-&gt;queue_bind($queue_name2, $exchange, 'bindingKey2'); $channel-&gt;queue_bind($queue_name3, $exchange, 'bindingKey2'); // 创建消息 $messageBody = '12345'; $message = new AMQPMessage($messageBody, array('content_type' =&gt; 'text/plain', 'delivery_mode' =&gt; AMQPMessage::DELIVERY_MODE_PERSISTENT)); // 发布消息 (这里,生产者在发布消息的时候,这个routingKey必须和后面消费者绑定的bindingKey一致 ) $channel-&gt;basic_publish($message, $exchange, 'bindingKey1'); $channel-&gt;close(); $connection-&gt;close();&#125; 如果消息能准确地被Exchange路由到正确的队列中, 即使没有消费者订阅队列, 消息也会一直在队列中等待有消费者来订阅并消费消息 ; Topic类型的Exchange :1.Topic类型的交换机在 消息发送到队列过程中 所使用的路由规则相比Direct类型来说稍微宽松了一点 ! 2.注意: 正则语法是用在绑定Exchange-queue的bindingKey上,而不是发送消息时的routingKey上 ; 3.测试: 代码 : 12345678910111213141516171819202122232425262728293031323334353637public function publisher()&#123; // 路由名称 $exchange = 'testRouter'; // 队列名称 $queue_name1 = 'queue1'; $queue_name2 = 'queue2'; $queue_name3 = 'queue3'; $queue_name4 = 'queue4'; // 连接RabbitMQ服务 $connection = new AMQPStreamConnection('localhost', '5672', 'guest', 'guest'); // 创建信道 $channel = $connection-&gt;channel(); // 声明一个路由 (topic类型) $channel-&gt;exchange_declare($exchange, 'topic', false, true, false); // 声明队列 (参数暂时不用了解) $channel-&gt;queue_declare($queue_name1, false, true, false, false); $channel-&gt;queue_declare($queue_name2, false, true, false, false); $channel-&gt;queue_declare($queue_name3, false, true, false, false); $channel-&gt;queue_declare($queue_name4, false, true, false, false); // 绑定路由和队列 $channel-&gt;queue_bind($queue_name1, $exchange, '*.bindingKey'); $channel-&gt;queue_bind($queue_name2, $exchange, 'bindingKey.*'); $channel-&gt;queue_bind($queue_name3, $exchange, 'bindingKey'); $channel-&gt;queue_bind($queue_name4, $exchange, 'bindingKey.#'); // 创建消息 $messageBody = '12345'; $message = new AMQPMessage($messageBody, array('content_type' =&gt; 'text/plain', 'delivery_mode' =&gt; AMQPMessage::DELIVERY_MODE_PERSISTENT)); $channel-&gt;basic_publish($message, $exchange, 'bindingKey'); $channel-&gt;close(); $connection-&gt;close();&#125; 效果 : Fanout类型的Exchange :1.相比严格的Direct来说就比较随意了, 只要绑定到fanout类型Exchange上的队列(bindingKey是什么并不重要), 都能收到publisher发布给这个Exchange的消息, 即使 发布消息时的routingKey 和 Exchange-Queue绑定时的bindingKey 不一致也无妨 ; 代码 : 1234567891011121314151617181920212223242526272829303132333435363738public function publisher()&#123; // 路由名称 $exchange = 'testRouter'; // 队列名称 $queue_name1 = 'queue1'; $queue_name2 = 'queue2'; $queue_name3 = 'queue3'; // 连接RabbitMQ服务 $connection = new AMQPStreamConnection('localhost', '5672', 'guest', 'guest'); // 创建信道 $channel = $connection-&gt;channel(); // 声明一个路由 (direct类型) $channel-&gt;exchange_declare($exchange, 'fanout', false, true, false); // 声明队列 (参数暂时不用了解) $channel-&gt;queue_declare($queue_name1, false, true, false, false); $channel-&gt;queue_declare($queue_name2, false, true, false, false); $channel-&gt;queue_declare($queue_name3, false, true, false, false); // 绑定路由和队列 $channel-&gt;queue_bind($queue_name1, $exchange, 'bindingKey1'); $channel-&gt;queue_bind($queue_name2, $exchange, 'bindingKey1'); $channel-&gt;queue_bind($queue_name3, $exchange, 'bindingKey1'); // 创建消息 $messageBody = '12345'; $message = new AMQPMessage($messageBody, array('content_type' =&gt; 'text/plain', 'delivery_mode' =&gt; AMQPMessage::DELIVERY_MODE_PERSISTENT)); // 发布消息 // 此时即使routingKey和bindingKey不一样也无妨 // fanout类型交换机会把收到的消息发送给所有和它绑定的队列, // 而不在乎是否发送消息时的routingKey 和 交换机绑定队列时的bindingKey 是否一致 $channel-&gt;basic_publish($message, $exchange, 'bindingKey2'); $channel-&gt;close(); $connection-&gt;close();&#125; 访问以下http://www.ls.net/publisher (我本地的生产者), 并通过rabbitmq提供的web界面进行测试","tags":[{"name":"rabbitmq","slug":"rabbitmq","permalink":"http://blog.renyimin.com/tags/rabbitmq/"},{"name":"php","slug":"php","permalink":"http://blog.renyimin.com/tags/php/"}]},{"title":"02-RabbitMQ基本架构","date":"2017-03-17T13:30:25.000Z","path":"2017/03/17/2017-03-17-rabbitmq-02/","text":"摘自网络的一张简单原理图 : 上图中的ClientA,B 其实就是上篇文章中提到的publisher(producer)生产者 上图中的Client1,2,3 consumer 消费者 Exchange1,2和Queue1,2 都是在RabbitMQ服务内部的 RoutingKey和BindingKey也进行了区分","tags":[{"name":"rabbitmq","slug":"rabbitmq","permalink":"http://blog.renyimin.com/tags/rabbitmq/"},{"name":"php","slug":"php","permalink":"http://blog.renyimin.com/tags/php/"}]},{"title":"01-认识RabbitMQ","date":"2017-03-17T04:10:25.000Z","path":"2017/03/17/2017-03-17-rabbitmq-01/","text":"1.RabbitMQ是一个由Erlang开发的AMQP的开源实现: 官网是 http://www.rabbitmq.com Erlang是一种通用的面向并发的编程语言, 它由瑞典电信设备制造商爱立信所辖的CS-Lab开发, 目的是创造一种可以应对大规模并发活动的编程语言和运行环境。 AMQP(Advanced Message Queuing Protocol), 一个提供统一消息服务的应用层标准高级消息队列协议, 是应用层协议的一个开放标准, 为面向消息的中间件设计。基于此协议的客户端与消息中间件可传递消息，并不受客户端/中间件不同产品，不同的开发语言等条件的限制。 AMQP 的出现其实也是应了广大人民群众的需求, 虽然在同步消息通讯的世界里有很多公开标准（如 COBAR的 IIOP ，或者是 SOAP 等），但是在异步消息处理中却不是这样，只有大企业有一些商业实现（如微软的 MSMQ ，IBM 的 Websphere MQ 等），因此，在 2006 年的 6 月，Cisco 、Redhat、iMatix 等联合制定了 AMQP 的公开标准。 2.RabbitMQ，或者说AMQP解决了什么问题，或者说它的应用场景是什么？ 你是否遇到过两个（多个）系统间需要通过定时任务来同步某些数据？ 你是否在为异构系统的不同进程间相互调用、通讯的问题而苦恼、挣扎？ 如果是，那么恭喜你，消息服务让你可以很轻松地解决这些问题。 消息服务擅长于解决多系统、异构系统间的数据交换（消息通知/通讯）问题，你也可以把它用于系统间服务的相互调用（RPC）。 AMDQ协议解决了以上的问题，而RabbitMQ实现了AMQP。 3.RabbitMQ的基本概念: vhost 每个virtual host本质上都是一个RabbitMQ Server，拥有它自己的queue，exchagne，和bindings rule等等, 这保证了你可以在多个不同的application中使用RabbitMQ ; RabbitMQ默认使用的是 / 这个vhost ; connect Connection 是RabbitMQ的socket链接，它封装了socket协议相关部分逻辑。 ConnectionFactory 为Connection的制造工厂。 channel Channel 是我们与RabbitMQ打交道的最重要的一个接口，我们大部分的业务操作是在Channel这个接口中完成的，包括定义Queue、定义Exchange、绑定Queue与Exchange、发布消息等。 为什么不直接通过TCP连接发送AMQP命令呢? 主要原因在对于操作系统来说建立和销毁TCP回话是非常昂贵的开销; 假设应用程序从队列消费消息, 并根据服务需求合理调度线程, 假设你进行的是TCP连接, 那么每个线程都需要自行连接到Rabbit, 而操作系统每秒建立的TCP连接数是有限的, 假设高峰期每秒有成百上千条连接, 这不仅造成TCP连接的巨大浪费, 而且操作系统没秒也就只能建立这点数量的连接。因此, 你可能很快就碰到性能瓶颈了； 如果让所有线程只使用一条TCP连接, 以满足性能方面的要求, 同时又能保证每个线程的私密性, 就像拥有独立TCP连接一样的话, 那不就非常完美了么? 这就引入了信道的概念, 线程启动后, 会在线程的连接上面创建一条信道, 也就获得了连接到Rabbit上的私密通信路径, 而不会给操作系统的TCP栈造成额外负担, 因此你可以每秒成百上千次的创建信道而不会影响操作系统, 在一条TCP连接上创建多少条信道是没有限制的, 可以把它想象成一束光纤电缆就可以 : publisher/producer producer负责创建消息, 然后发布消息到RabbitMQ服务器 exchange(交换器): 是RabbitMQ的内部对象, 用于路由消息到queue; producer创建的消息发送到RabbitMQ服务器之后, RabbitMQ服务器并不知道producer的消息需要发送给哪个queue, 所以RabbitMQ也不会直接将消息投递到某个队列中; 在RabbitMQ中, 生产者将消息投递到Queue中, 这种事情永远都不会发生; 实际的情况是，生产者将消息发送到RabbitMQ内部的Exchange, 然后由Exchange将消息路由到一个或多个与其通过bindingKey绑定的Queue中; 消息被Exchange接收以后，如果没有匹配的Queue，则消息会被丢弃! RabbitMQ常用的Exchange Type有fanout、direct、topic、headers这四种, 不过headers类型并不太实用, 而且性能比较差, 几乎再也用不到了 。 queue(队列): 是RabbitMQ的内部对象, 用于存储消息 ; RabbitMQ中的消息都只能存储在Queue中，生产者生产消息并通过Exchange(交换机)最终投递到Queue中。 注意: 同一个vhost下,声明同名队列, 但是参数不同, 会出现什么情况? 会报错! consumer(消费者, 订阅者): 多个消费者可以订阅同一个Queue，这时Queue中的消息会被平均分摊给多个消费者进行处理，而不是每个消费者都收到所有的消息并处理; Message acknowledgment(消息确认 ack) 在实际应用中,可能会发生消费者收到Queue中的消息,但没有处理完成就宕机（或出现其他意外）的情况,这种情况下就可能会导致消息丢失。 为了避免这种情况发生,我们可以要求消费者在消费完消息后发送一个回执给RabbitMQ,RabbitMQ收到消息回执（Message acknowledgment）后才将该消息从Queue中移除;如果RabbitMQ没有收到回执并检测到消费者的RabbitMQ连接断开,则RabbitMQ会将该消息发送给其他消费者（如果存在多个消费者）进行处理。这里不存在timeout概念,一个消费者处理消息时间再长也不会导致该消息被发送给其他消费者。 这里会产生另外一个问题,如果我们的开发人员在处理完业务逻辑后,忘记发送回执给RabbitMQ,这将会导致严重的bug——Queue中堆积的消息会越来越多; 虽然消费者重启后会重复消费这些消息并重复执行业务逻辑。 注意: 消息确认中 no-ack属性的设置 no_ack=false : 此时为手动应答 在这种情况下，要求 consumer 在 处理完 接收到的 Basic.Deliver + Content-Header + Content-Body 之后才回复 Ack 。而这个 Ack 是 AMQP 协议中的 Basic.Ack 。此 Ack 的回复是和业务处理相关的，所以具体的回复时间应该要取决于业务处理的耗时。 1234//设置消费者消费消息为手动消费:$channel-&gt;basic_consume($queue, $consumerTag, false, false, false, false, $backCall);//然后在回调函数中,手动ack :$req-&gt;delivery_info['channel']-&gt;basic_ack($req-&gt;delivery_info['delivery_tag']); no_ack=true: 此时为自动应答 在这种情况下，consumer 会在 接收到 Basic.Deliver + Content-Header + Content-Body 之后，立即回复 Ack 。而这个 Ack 是 TCP 协议中的 Ack 。此 Ack 的回复不关心 consumer 是否对接收到的数据进行了处理，当然也不关心处理数据所需要的耗时 (目前常使用前者) 消息拒绝 reject 既然RabbitMQ提供了ACK某一个消息的命令,当然也提供了Reject某一个消息的命令。 当客户端发生错误,调用basic.reject命令拒绝某一个消息时,可以设置一个requeue的属性: 如果为true,则消息服务器会重传该消息给下一个订阅者; 如果为false,则会直接删除该消息; 当然,也可以通过ack,让消息服务器直接删除该消息并且不会重传。 4.RoutingKey, BindingKey 真实情况下, 参数名都是RoutingKey，并没有BindingKey这个参数，为了区别 生产者发送消息时 和 Exchange-Queue绑定时 的概念，我们才说RoutingKey和BindingKey; bindingKey: 在绑定（Binding）Exchange与Queue的时候，一般会指定一个RoutingKey, 为了区分下面的RoutingKey, 此时这个RoutingKey叫BindingKey; routingKey: 消费者将消息发送给Exchange时, 一般会指定一个RoutingKey, 当BindingKey与RoutingKey相匹配时，生产者发送的消息才将会被路由到对应的Queue中; 在bind多个Queue到同一个Exchange的时候，这些Binding允许使用相同的BindingKey; BindingKey并不是在所有情况下都生效，它依赖于Exchange Type，比如fanout类型的Exchange就会无视绑定时的BindingKey, 会直接将消息路由到所有绑定到该fanout-Exchange的Queues。 5.RabbitMQ中 用户和vhost之间的关系: 可以创建用户并且给用户分配vhost作用域, 用户和vhost作用域之间是多对多的分配关系 可以在连接Rabbit服务的时候指定用户和作用域, 如下 : // 主机地址, 端口, Rabbit用户, 密码, 分配给Rabbit用户的vhost域 $connection = new AMQPStreamConnection(&apos;localhost&apos;, &apos;5672&apos;, &apos;tt&apos;, &apos;tt&apos;, &apos;test&apos;); 参考: http://www.rabbitmq.com/amqp-0-9-1-reference.html#domain.no-local","tags":[{"name":"rabbitmq","slug":"rabbitmq","permalink":"http://blog.renyimin.com/tags/rabbitmq/"},{"name":"php","slug":"php","permalink":"http://blog.renyimin.com/tags/php/"}]},{"title":"01-MySQL主从复制原理","date":"2016-11-15T04:20:05.000Z","path":"2016/11/15/2016-11-15-mysql-master-slave-01/","text":"1.主从复制 replication 原理 : master服务器上进行sql写语句操作的时候, 是会引起磁盘变化的 ; 所以slave服务器要想和master上的数据保持一致, 可以有两种办法 : slave按照master服务器上每次的sql写语句来执行一遍; slave按照master服务器上磁盘的变化来做一次变化 ; 2.主服务器 master 上的写操作都会被记录到 binlog 二进制日志中 ;从服务器 slave 去读主服务器的 binlog 二进制日志, 形成自己的relay中继日志中, 然后执行一遍中继日志中的操作 ; 3.所以 : 主服务器要配置binlog二进制 从服务器要配置relaylog(中继日志) 从服务器如何有权读取主服务器的binlog (binlog非常敏感, 不可能让某个用户去随便读) 所以master要授予slave账号 ; 从服务器用账号连接master ; 从服务器一声令下开启同步功能 start slave ; 4.注意: 一般会在集群中的每个sql服务器中加一个server-id来做唯一标识 ;","tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://blog.renyimin.com/tags/MySQL/"}]},{"title":"10-依赖注入","date":"2016-10-12T03:30:02.000Z","path":"2016/10/12/2016-10-12-OOP-10/","text":"依赖注入1.依赖注入的引入: 在Web开发中,HTTP本身是一个无状态的连接协议,为了支持客户在发起WEB请求时,应用程序能存储用户信息, 很多情况下都会使用PHP内置的Session机制, 假设现在有一个SessionStorage类, 该类封装了PHP Session机制:1234567891011121314151617181920class SessionStorage&#123; function __construct($cookieName = 'PHP_SESS_ID') &#123; session_name($cookieName); session_start(); &#125; function set($key, $value) &#123; $_SESSION[$key] = $value; &#125; function get($key) &#123; return $_SESSION[$key]; &#125; // ...&#125; 在用户类中就可以如下来使用SessionStorage类:12345678910111213141516171819202122232425class User&#123; protected $storage; function __construct() &#123; $this-&gt;storage = new SessionStorage(); &#125; function setLanguage($language) &#123; $this-&gt;storage-&gt;set('language', $language); &#125; function getLanguage() &#123; return $this-&gt;storage-&gt;get('language'); &#125;&#125;//可以看到,代码很简单,并且使用User类也很简单,如下就可以完成用户session的存储$user = new User();$user-&gt;setLanguage('English');$user_language = $user-&gt;getLanguage(); 假设现在你想要更改保存session_id的COOKIE键值,以下有一些可供选择的方法:1234567891011121314151617181920212223242526272829303132333435363738391.User类中创建SessionStorage实例时,在SessionStorage构造方法中使用字符串'SESSION_ID'硬编码:class User&#123; function __construct() &#123; $this-&gt;storage = new SessionStorage('SESSION_ID'); &#125; // ...&#125;2. 在User类外部设置一个常量(名为STORAGE_SESSION_NAME)define('STORAGE_SESSION_NAME', 'SESSION_ID');class User&#123; function __construct() &#123; $this-&gt;storage = new SessionStorage(STORAGE_SESSION_NAME); &#125;&#125;3.通过User类构造函数中的参数传递Session name class User &#123; function __construct($sessionName) &#123; $this-&gt;storage = new SessionStorage($sessionName); &#125; &#125;4.通过User类构造函数中的参数传递Session name,不过这次参数采用数组的方式class User&#123; function __construct($storageOptions) &#123; $this-&gt;storage = new SessionStorage($storageOptions['session_name']); &#125;&#125;$user = new User(array('session_name' =&gt; 'SESSION_ID')); 上面的方式都很糟糕: 在user类中硬编码设置session name的做法没有真正解决问题; 使用常量的方式同样很糟, 造成User类依赖于一个常量设置; 通过User类构造函数的参数或数组来传递session name相对来说好一些, 不过也不完美, 这样做干扰了User类构造函数的参数, 因为如何存储Session并不是User类需要关心的,User类不应该和它们扯上关系; 另外,还有一个问题不太好解决: 我们如何改变User类中所使用的SessionStorage类,这种应用场景很多,比如你要将Session存储在数据库或者内存中。目前这种实现方式,在不改变User类的情况下,很难做到这点; 2.现在尝试来使用依赖注入, 之前是在User类内部创建SessionStorage对象的, 现在修改一下, 让SessionStorage对象通过User类的构造函数传递进去:12345678910111213class User&#123; function __construct($storage) &#123; $this-&gt;storage = $storage; &#125;&#125;//这就是依赖注入最经典的案例,没有之一//现在使用User类有一些小小的改变,首先你需要创建SessionStorage对像$storage = new SessionStorage('SESSION_ID');$user = new User($storage); 现在,配置session存储对像很简单了,同样如果改变session存储对像也很简单,所有这一切并不需要去更新User类,降低了业务类之间的耦合。 3.Pico Container 的网站上是这样描述依赖注入: 依赖注入是通过类的构造函数、方法、或者直接写入的方式, 将所依赖的组件传递给类的方式。 所以依赖注入并不只限于通过构造函数注入。下面来看看几种注入方式:1234567891011121314151617181920212223242526272829构造函数注入class User&#123; function __construct($storage) &#123; $this-&gt;storage = $storage; &#125; // ...&#125;setter方法注入class User&#123; function setSessionStorage($storage) &#123; $this-&gt;storage = $storage; &#125; // ...&#125;属性直接注入class User&#123; public $sessionStorage;&#125;$user-&gt;sessionStorage = $storage; 根据经验, 一般通过构造函数注入的是强依赖关系的组件, setter方式用来注入可选的依赖组件。4.大多数流行的PHP框架都采用了依赖注入的模式实现业务组件间的高内聚低耦合:12345678910111213141516// symfony: 构造函数注入的例子$dispatcher = new sfEventDispatcher();$storage = new sfMySQLSessionStorage(array('database' =&gt; 'session', 'db_table' =&gt; 'session'));$user = new sfUser($dispatcher, $storage, array('default_culture' =&gt; 'en'));// Zend Framework: setter方式注入的例子$transport = new Zend_Mail_Transport_Smtp('smtp.gmail.com', array( 'auth' =&gt; 'login', 'username' =&gt; 'foo', 'password' =&gt; 'bar', 'ssl' =&gt; 'ssl', 'port' =&gt; 465,));$mailer = new Zend_Mail();$mailer-&gt;setDefaultTransport($transport); 如果对依赖注入有兴趣，强烈推荐你看《Martin Fowler introduction》或者著名的《Jeff More presentation》希望对大家在理解依赖注入上有所帮助。在后面的内容中，我们将讨论依赖注入的容器实现。","tags":[{"name":"OOP","slug":"OOP","permalink":"http://blog.renyimin.com/tags/OOP/"},{"name":"依赖注入","slug":"依赖注入","permalink":"http://blog.renyimin.com/tags/依赖注入/"}]},{"title":"01-webpack入门","date":"2016-10-07T10:20:15.000Z","path":"2016/10/07/2016-10-08-webpack-01/","text":"","tags":[{"name":"webpack","slug":"webpack","permalink":"http://blog.renyimin.com/tags/webpack/"}]},{"title":"01-vuejs","date":"2016-10-07T10:20:15.000Z","path":"2016/10/07/2016-10-07-VueJS-01/","text":"一. Vue.js 是什么Vue.js（读音 /vjuː/, 类似于 view） 是一套构建用户界面的 渐进式框架。与其他重量级框架不同的是，Vue 采用自底向上增量开发的设计。Vue 的核心库只关注视图层，并且非常容易学习，非常容易与其它库或已有项目整合。另一方面，Vue 完全有能力驱动采用单文件组件和Vue生态系统支持的库开发的复杂单页应用; Vue.js 的目标是通过尽可能简单的 API 实现响应的数据绑定和组合的视图组件; Vue.js是一个MVVM模式的框架，如果读者有angular经验，一定能够很快入门Vue的; 二. vue.js的特点: 易用: 已经会了HTML,CSS,JavaScript？即刻阅读指南即可开始构建应用; 灵活: 简单小巧的核心,渐进式技术栈,足以应付任何规模的应用; 高效: 6kb min+gzip 的运行大小,超快虚拟 DOM ,最省心的优化; 三. MVC、MVP、MVVM（Model-View-ViewModel）1.MVCMVC（Model-View-Controller）MVC是比较直观的架构模式，用户操作-&gt;View（负责接收用户的输入操作）-&gt;Controller（业务逻辑处理）-&gt;Model（数据持久化）-&gt;View（将结果反馈给View）。 MVC使用非常广泛，比如JavaEE中的SSH框架（Struts/Spring/Hibernate），Struts（View, STL）-Spring（Controller, Ioc、Spring MVC）-Hibernate（Model, ORM）以及ASP.NET中的ASP.NET MVC框架，xxx.cshtml-xxxcontroller-xxxmodel。（实际上后端开发过程中是v-c-m-c-v，v和m并没有关系，下图仅代表经典的mvc模型） 2.MVPMVP是把MVC中的Controller换成了Presenter（呈现），目的就是为了完全切断View跟Model之间的联系，由Presenter充当桥梁，做到View-Model之间通信的完全隔离。 .NET程序员熟知的ASP.NET webform、winform基于事件驱动的开发技术就是使用的MVP模式。控件组成的页面充当View，实体数据库操作充当Model，而View和Model之间的控件数据绑定操作则属于Presenter。控件事件的处理可以通过自定义的IView接口实现，而View和IView都将对Presenter负责。 3.MVVM（Model-View-ViewModel）如果说MVP是对MVC的进一步改进，那么MVVM则是思想的完全变革。它是将“数据模型数据双向绑定”的思想作为核心，因此在View和Model之间没有联系，通过ViewModel进行交互，而且Model和ViewModel之间的交互是双向的，因此视图的数据的变化会同时修改数据源，而数据源数据的变化也会立即反应到View上。 这方面典型的应用有.NET的WPF，js框架Knockout、AngularJS等。 四. 环境搭建(windows下):1.所需Tools : NodeJs: javascript运行环境(runtime); npm: Nodejs下的包管理器。由于国内使用npm会很慢,这里推荐使用淘宝NPM镜像（http://npm.taobao.org/） $ npm install -g cnpm --registry=https://registry.npm.taobao.org webpack: 它主要的用途是通过 CommonJS 的语法把所有浏览器端需要发布的静态资源做相应的准备，比如资源的合并和打包。 vue-cli: 用户生成Vue工程模板 2.NodeJs安装:从node.js官网下载并安装node (windows下自然是.msi包);安装过程很简单，一路“下一步”就可以了（傻瓜式安装）;安装完成之后，打开命令行工具，输入 node -v，如下图，如果出现相应的版本号，则说明安装成功。 3.npm包管理器是集成在node中的，所以安装完nodejs之后,直接输入 npm -v 就会如下图所示,显示出npm的版本信息:node环境已经安装完成, npm包管理器也有了。由于有些npm有些资源被屏蔽或者是国外资源的原因,经常会导致用npm安装依赖包的时候失败,所有还需要npm的国内镜像 : cnpm ; 4.cnpm在命令行中输入 npm install -g cnpm –registry=http://registry.npm.taobao.org 然后等待安装完成完成之后，我们就可以用cnpm代替npm来安装依赖包了。 5.安装vue-cli脚手架构建工具在命令行中运行命令 npm install -g vue-cli , 然后等待安装完成:通过以上步骤,我们需要准备的环境和工具都准备好了, 接下来就开始使用vue-cli来构建项目; 6.用vue-cli构建项目要创建项目，首先要选定目录，然后在命令行中把目录转到选定的目录。在这里，我选择G:\\来存放新建的项目,则我们需要先把目录cd到G:\\，如下图(g盘目前还没有testVue目录): 然后,在命令行中运行命令 vue init webpack testVue ,解释一下这个命令，这个命令的意思是初始化一个项目，其中webpack是构建工具，也就是整个项目是基于webpack的。其中testVue是整个项目文件夹的名称，这个文件夹会自动生成在你指定的目录中,如下图: 运行初始化命令的时候回让用户输入几个基本的选项，如项目名称，描述，作者等信息，如果不想填直接回车默认就 注意:Projectname不能包含大写字母, 否则会报错 安装完成后,会在G盘下生成vue项目目录: 这就是整个项目的目录结构，其中，我们主要在src目录中做修改。这个项目现在还只是一个结构框架，整个项目需要的依赖资源都还没有安装，如下图: 7.安装项目所需的依赖要安装依赖包，首先cd到项目文件夹（testVue文件夹），然后运行命令 cnpm install ，等待安装。安装完成之后，会在我们的项目目录firstVue文件夹中多出一个node_modules文件夹，这里边就是我们项目需要的依赖包资源。 8.运行项目在项目目录中，运行命令 npm run dev ，会用热加载的方式运行我们的应用，热加载可以让我们在修改完代码后不用手动刷新浏览器就能实时看到修改后的效果。 这里简单介绍下 npm run dev 命令，其中的“run”对应的是package.json文件中，scripts字段中的dev，也就是 node build/dev-server.js命令的一个快捷方式。项目运行成功后，浏览器会自动打开localhost:8080（如果浏览器没有自动打开，可以手动输入）。运行成功后，会看到如下所示的界面:","tags":[{"name":"vuejs","slug":"vuejs","permalink":"http://blog.renyimin.com/tags/vuejs/"}]},{"title":"01-认识MongoDB","date":"2016-05-23T13:17:31.000Z","path":"2016/05/23/2016-05-23-MongoDB-01/","text":"简介MongoDB 是一个基于分布式文件存储的数据库,由 C++ 语言编写,旨在为 WEB 应用提供可扩展的高性能数据存储解决方案; MongoDB 是一个介于关系数据库和非关系数据库之间的产品，是非关系数据库当中功能最丰富，最像关系数据库的; 不使用的场景: 1、高度事物性的系统:银行系统 2、需要高度优化查询的数据 3、重要的数据 4、需要复杂SQL解决的问题 Variety Variety是一个开源的，非常使用的，检测mongodb表字段类型、分布的一个开源工具。 正如其github readme中第一句所说”Meet Variety, a Schema Analyzer for MongoDB”","tags":[{"name":"MongoDB","slug":"MongoDB","permalink":"http://blog.renyimin.com/tags/MongoDB/"}]},{"title":"存储密码","date":"2016-01-11T03:20:02.000Z","path":"2016/01/11/2016-01-11-web_safe-01/","text":"存储密码1.使用 phpass 库来哈希和比较密码经 phpass 0.3 测试,在存入数据库之前进行哈希保护用户密码的标准方式。许多常用的哈希算法如 md5, 甚至是 sha1 对于密码存储都是不安全的, 因为骇客能够使用那些算法轻而易举地破解密码。 对密码进行哈希最安全的方法是使用 bcrypt 算法。开源的 phpass 库以一个易于使用的类来提供该功能:示例:1234567891011121314151617&lt;?php// Include phpass 库require_once('phpass-03/PasswordHash.php')// 初始化散列器为不可移植(这样更安全)$hasher = new PasswordHash(8, false);// 计算密码的哈希值。$hashedPassword 是一个长度为 60 个字符的字符串.$hashedPassword = $hasher-&gt;HashPassword('my super cool password');// 你现在可以安全地将 $hashedPassword 保存到数据库中!// 通过比较用户输入内容（产生的哈希值）和我们之前计算出的哈希值，来判断用户是否输入了正确的密码$hasher-&gt;CheckPassword('the wrong password', $hashedPassword); // false$hasher-&gt;CheckPassword('my super cool password', $hashedPassword); // true?&gt; 陷阱:许多资源可能推荐你在哈希之前对你的密码“加盐”。想法很好,但 phpass 在 HashPassword() 函数中已经对你的密码“加盐”了, 这意味着你不需要自己“加盐”。 另外google已经于2017.02.23日攻破SHA1算法; 注意: Laravel 的 Hash 门面 为存储用户密码提供了安全的 Bcrypt 哈希算法。 如果你正在使用 Laravel 应用自带的 LoginController 和RegisterController 控制器, 它们将会自动在注册和认证时使用该 Bcrypt 。 基本使用 (可以调用 Hash 门面上的 make 方法对存储密码进行哈希):12345678910111213141516171819202122232425&lt;?phpnamespace App\\Http\\Controllers;use Illuminate\\Http\\Request;use Illuminate\\Support\\Facades\\Hash;use App\\Http\\Controllers\\Controller;class UpdatePasswordController extends Controller&#123; /** * 更新用户密码. * * @param Request $request * @return Response */ public function update(Request $request) &#123; // 验证新密码长度... $request-&gt;user()-&gt;fill([ 'password' =&gt; Hash::make($request-&gt;newPassword) ])-&gt;save(); &#125;&#125; 进一步阅读:为什么使用 md5 或 sha 哈希密码是不安全的怎样安全地存储密码Laravel文档","tags":[{"name":"safe","slug":"safe","permalink":"http://blog.renyimin.com/tags/safe/"},{"name":"Laravel","slug":"Laravel","permalink":"http://blog.renyimin.com/tags/Laravel/"}]},{"title":"NGINX信号控制","date":"2015-07-21T16:00:00.000Z","path":"2015/07/22/2015-07-22-nginx-02/","text":"一. 控制nginx服务的启停有不止一种方法,下面先使用 nginx服务的信号控制1.上节已经编译安装了Nginx, 并且顺利启动 , 那如果要停止/重启Nginx怎么办 ? nginx的开启: ./nginx 那重启和关闭现在就可以先使用下面的 nginx信号量 ! 2.nginx 的信号控制, 向Nginx主进程发送信号有两种方法 : 一种是使用Nginx二进制文件, 以后再讲 ; 另一种方法是使用kill命令发送信号, 用法是: kill -SIGNAL PID 二.kill命令发送信号:1.INT / TERM 查看nginx服务进程 : ps aux | grep nginx nginx有一个主进程文件,它不直接响应浏览器请求,而是用来管理子进程; 当有浏览器进行请求的时候,由子进程负责响应, 主进程负责控制子进程; 所以可以看到nginx服务有master process主进程, 也有worker process 这个干活的进程 ! 对nginx进程施加影响: kill -INT/TERM 3321(主进程号) 注意: Term或INT, 轻易不用, 它俩都会直接关闭进程; 2.QUIT 平滑重启nginx 3.HUP 平滑读取新配置文件, 并开启新进程, 然后优雅地关闭旧进程 在修改完nginx的配置文件之后是需要重启生效的, 此处可以使用 kill -HUP nginx主进程号 4.USR1 信号 : kill -USR1 主进程号 重新打开日志文件, 可用于日志切割 在把自定义日志文件重新删除之后, 重新创建一个新的自定义服务日志文件的话, 即使名字完全一样, 我们发现这个新的自定义服务日志文件并不会进行用户访问信息的记录, 除非重启nginx服务; 其实这个时候就需要用到USR1信号量了, 对于新建的同名日志文件(可能文件的id并不同, 所以需要nginx平缓重新确定一下日志文件) : 切割nginx日志脚本(日志部分探讨) : 5.USR2 信号 和 WHICH 信号配合起来使用(以后探讨) ; 三.nginx也提供了一些命令操作 -v : 打印版本号并退出 -V : 打印版本号和配置并退出 -t : 测试配置正确性并退出, (在配置正确的时候, 也会进行如下提示, 而-qt只在配置出错的情况下有提示) ( 有时候还会配合-c参数, 用来指定配置文件的路径；当然, 默认情况下会使用nginx安装目录下的conf/nginx.conf,所以-c参数也不多使用) -q : 测试配置时只显示错误, 所以 -q 和 -t 一起连用的时候, 如果配置文件无错误的话, 将不会输出上面-t时的内容 : -s signal : 用来向nginx服务的主进程发送信号: ./nginx -s stop – 对应的信号量的 kill -INT PID./nginx -s quit – 百度: 完整有序的停止nginx 对应信号量的 kill -QUIT PID./nginx -s reload ( 明显是重读配置文件 ) – 对应的信号量的 kill -HUP PID./nginx -s reopen – 重新打开日志文件 对应信号量 kill -USR1 PID","tags":[{"name":"nginx","slug":"nginx","permalink":"http://blog.renyimin.com/tags/nginx/"}]},{"title":"NGINX初探","date":"2015-07-19T16:00:00.000Z","path":"2015/07/20/2015-07-20-nginx-01/","text":"一. 百科[百科] (http://baike.baidu.com/link?url=kmtYsfJ882-y_ByHCrG61vm-GVGCltiCaMFaAyX49FeZ6RjFcT49WApZivglDhgObGI0PJGxYFni7N7to9deKq) 二. 简介1.nginx的下载: nginx的官方网站下载 : http://nginx.org/en/download.html nginx的历史版本下载 : http://nginx.org/download nginx官网提供了三个类型的版本: Mainline version：Mainline 是 Nginx 目前主力在做的版本，可以说是开发版 Stable version：最新稳定版，生产环境上建议使用的版本 Legacy versions：遗留的老版本的稳定版 ( 历史稳定版 ) 2.准备: cd /usr/local/src mkdir nginx cd /usr/local/src/nginx wget http://nginx.org/download/nginx-1.8.0.tar.gz tar -zxvf nginx-1.8.0.tar.gz 由于nginx的一些模块需要依赖第三方库, 通常有pcre库(支持rewrite模块), zlib库(支持gzip模块) 和 openssl库(支持ssl (Secure Sockets Layer 安全套接层) 模块)等 :（yum安装即可） yum -y install gcc gcc-c++ automake pcre pcre-devel zlib zlib-devel open openssl-devel 这样就完成了安装nginx服务的准备工作 ; 3.开始编译, 安装: ./configure --prefix=/usr/local/nginx (生成 Makefile 文件) make &amp;&amp; make install 目录结构: conf : 配置文件 html : 网页文件 logs : 日志文件 sbin : 主要二进制程序 启动nginx : cd /usr/local/nginx ./nginx 之后便可进行访问;","tags":[{"name":"nginx","slug":"nginx","permalink":"http://blog.renyimin.com/tags/nginx/"}]}]